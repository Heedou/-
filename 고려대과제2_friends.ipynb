{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "고려대과제2_friends",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOAgXVSL6V11QAwcQHk5JLf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Heedou/-/blob/main/%EA%B3%A0%EB%A0%A4%EB%8C%80%EA%B3%BC%EC%A0%9C2_friends.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QCJOeg2D1w32",
        "outputId": "e3f4670d-6651-4f95-bcf5-371d89d0b9b6"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/50/0c/7d5950fcd80b029be0a8891727ba21e0cd27692c407c51261c3c921f6da3/transformers-4.1.1-py3-none-any.whl (1.5MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5MB 18.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.8)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 55.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.19.4)\n",
            "Collecting tokenizers==0.9.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/1c/e789a8b12e28be5bc1ce2156cf87cb522b379be9cadc7ad8091a4cc107c4/tokenizers-0.9.4-cp36-cp36m-manylinux2010_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 53.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.0.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=4491383f4c7cce5896cfb46403defb53485f1c3ee3ea3ca0610ac9115366337e\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.43 tokenizers-0.9.4 transformers-4.1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5J6ggrK1tgj"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "from transformers import *\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import json\r\n",
        "import os"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N1aFykfU15yh",
        "outputId": "26d51070-5b46-485d-a2b3-e125d103001f"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lyOtW-yC9n-s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21aeb52f-2ac0-4f5e-a408-f80a274e7932"
      },
      "source": [
        "os.listdir('/content/gdrive/My Drive/Colab Notebooks/naver_sentiment/Friends')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['friends_train.json',\n",
              " 'friends_dev.json',\n",
              " 'friends_test.json',\n",
              " 'best_model.h5']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_mFYuGW-kXY"
      },
      "source": [
        "#json 파일 형태의 friends 데이터 불러오기\n",
        "with open('/content/gdrive/My Drive/Colab Notebooks/naver_sentiment/Friends/friends_train.json', 'r') as f:\n",
        "  train_friends_dic = json.load(f)\n",
        "\n",
        "with open('/content/gdrive/My Drive/Colab Notebooks/naver_sentiment/Friends/friends_test.json', 'r') as f:\n",
        "  test_friends_dic = json.load(f)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2vUN4-p-qLq"
      },
      "source": [
        "# 데이터 프레임 형태로 고치기\n",
        "data_all = []\n",
        "for i in range(len(train_friends_dic)):\n",
        "  for j in range(len(train_friends_dic[i])):\n",
        "    data = (train_friends_dic[i][j]['utterance'], train_friends_dic[i][j]['emotion'])\n",
        "    data_all.append(data)\n",
        "\n",
        "train_friends = pd.DataFrame(data_all)\n",
        "train_friends.columns = ['text', 'label']\n",
        "train_friends = train_friends.dropna()\n",
        "\n",
        "data_all2 = []\n",
        "for i in range(len(test_friends_dic)):\n",
        "  for j in range(len(test_friends_dic[i])):\n",
        "    data = (test_friends_dic[i][j]['utterance'], test_friends_dic[i][j]['emotion'])\n",
        "    data_all2.append(data)\n",
        "\n",
        "test_friends = pd.DataFrame(data_all2)\n",
        "test_friends.columns = ['text', 'label']\n",
        "test_friends = test_friends.dropna()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_r2cCcW_G7D"
      },
      "source": [
        "# 알파벳 이외의 문자 제거하는 정제작업\n",
        "train_friends_text = [i for i in train_friends['text']]\n",
        "train_cleaned_friends_texts = []\n",
        "for text in train_friends_text:\n",
        "  try:\n",
        "    text = re.sub('[^a-zA-Z\\\\s]', '', text)\n",
        "  except:\n",
        "    pass\n",
        "\n",
        "  train_cleaned_friends_texts.append(text)\n",
        "\n",
        "test_friends_text = [i for i in test_friends['text']]\n",
        "test_cleaned_friends_texts = []\n",
        "for text in test_friends_text:\n",
        "  try:\n",
        "    text = re.sub('[^a-zA-Z\\\\s]', '', text)\n",
        "  except:\n",
        "    pass\n",
        "\n",
        "  test_cleaned_friends_texts.append(text)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5sE7xmd_QV9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e467fe34-060d-4f91-aa62-24381b734cfe"
      },
      "source": [
        "len_friends = [len(i) for i in train_cleaned_friends_texts if type(i)==str]\n",
        "print('friends 리뷰 길이의 최대값 : {}'.format(np.max(len_friends)))\n",
        "print('friends 리뷰 길이의 최소값 : {}'.format(np.min(len_friends)))\n",
        "print('friends 리뷰 길이의 평균 : {}'.format(np.mean(len_friends)))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "friends 리뷰 길이의 최대값 : 327\n",
            "friends 리뷰 길이의 최소값 : 1\n",
            "friends 리뷰 길이의 평균 : 39.68478363791308\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cyKo6KRmxKIS"
      },
      "source": [
        "train_friends"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vk2nD2LK_W8O"
      },
      "source": [
        "# friends 데이터의 경우, label을 숫자로 바꾸어 주어야 함. 우선 label의 개수 확인\n",
        "train_labels = [i for i in train_friends['label']]\n",
        "train_labels = list(set(train_labels))\n",
        "train_labels\n",
        "# label 확인 결과, disgust, anger, fear, sadness, non-neutral, neutral, surprise, joy 등의 8개의 감정이 존재\n",
        "# 각각의 감정에 해당하는 label을 숫자로 대체하기\n",
        "for i in range(len(train_friends)):\n",
        "  if train_friends['label'][i] == 'non-neutral':\n",
        "    train_friends['label'][i] = 0\n",
        "  elif train_friends['label'][i] == 'neutral':\n",
        "    train_friends['label'][i] = 1\n",
        "  elif train_friends['label'][i] == 'joy':\n",
        "    train_friends['label'][i] = 2\n",
        "  elif train_friends['label'][i] == 'sadness':\n",
        "    train_friends['label'][i] = 3\n",
        "  elif train_friends['label'][i] == 'fear':\n",
        "    train_friends['label'][i] = 4\n",
        "  elif train_friends['label'][i] == 'anger':\n",
        "    train_friends['label'][i] = 5\n",
        "  elif train_friends['label'][i] == 'surprise':\n",
        "    train_friends['label'][i] = 6\n",
        "  elif train_friends['label'][i] == 'disgust':\n",
        "    train_friends['label'][i] = 7"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e0rc2yMOIfQy"
      },
      "source": [
        "# friends 데이터의 경우, label을 숫자로 바꾸어 주어야 함. 우선 label의 개수 확인\r\n",
        "test_labels = [i for i in test_friends['label']]\r\n",
        "test_labels = list(set(test_labels))\r\n",
        "test_labels\r\n",
        "# label 확인 결과, disgust, anger, fear, sadness, non-neutral, neutral, surprise, joy 등의 8개의 감정이 존재\r\n",
        "# 각각의 감정에 해당하는 label을 숫자로 대체하기\r\n",
        "for i in range(len(test_friends)):\r\n",
        "  if test_friends['label'][i] == 'non-neutral':\r\n",
        "    test_friends['label'][i] = 0\r\n",
        "  elif test_friends['label'][i] == 'neutral':\r\n",
        "    test_friends['label'][i] = 1\r\n",
        "  elif test_friends['label'][i] == 'joy':\r\n",
        "    test_friends['label'][i] = 2\r\n",
        "  elif test_friends['label'][i] == 'sadness':\r\n",
        "    test_friends['label'][i] = 3\r\n",
        "  elif test_friends['label'][i] == 'fear':\r\n",
        "    test_friends['label'][i] = 4\r\n",
        "  elif test_friends['label'][i] == 'anger':\r\n",
        "    test_friends['label'][i] = 5\r\n",
        "  elif test_friends['label'][i] == 'surprise':\r\n",
        "    test_friends['label'][i] = 6\r\n",
        "  elif test_friends['label'][i] == 'disgust':\r\n",
        "    test_friends['label'][i] = 7"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVQgrfUY2sjg"
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y7ZO9oNU4qIt",
        "outputId": "76699ae3-95f8-4512-8674-aa305e9bfc4c"
      },
      "source": [
        "tokens = []\r\n",
        "masks = []\r\n",
        "segments = []\r\n",
        "labels = []\r\n",
        "max_sequence_length = 64\r\n",
        "for i in range(len(train_friends)):\r\n",
        "  text = str(train_friends['text'][i])\r\n",
        "  label = train_friends['label'][i]\r\n",
        "\r\n",
        "  #token 만드는 부분\r\n",
        "  token = tokenizer.encode(text, max_length=max_sequence_length, pad_to_max_length=True)\r\n",
        "  for index, value in enumerate(token):\r\n",
        "    if value == 1:\r\n",
        "        token[index] = 0\r\n",
        "\r\n",
        "  #mask 만드는 부분\r\n",
        "  zeros = token.count(0)\r\n",
        "  mask = [1]*(max_sequence_length-zeros) + [0]*zeros\r\n",
        "\r\n",
        "  #segment 만드는 부분\r\n",
        "  segment = [0]*max_sequence_length\r\n",
        "\r\n",
        "\r\n",
        "  #각 리스트에 저장\r\n",
        "  tokens.append(token)\r\n",
        "  masks.append(mask)\r\n",
        "  segments.append(segment)\r\n",
        "  labels.append(label)\r\n",
        "\r\n",
        "# numpy array로 변경\r\n",
        "tokens = np.array(tokens)\r\n",
        "masks = np.array(masks)\r\n",
        "segments = np.array(segments)\r\n",
        "labels = np.array(labels)\r\n",
        "\r\n",
        "train_x = [tokens, masks, segments]\r\n",
        "train_y = labels"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2179: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GirM3UkI5MvS",
        "outputId": "b23c811b-3ef0-47ce-c4e5-17a6c397e069"
      },
      "source": [
        "test_tokens = []\r\n",
        "test_masks = []\r\n",
        "test_segments = []\r\n",
        "test_labels = []\r\n",
        "max_sequence_length = 64\r\n",
        "for i in range(len(test_friends)):\r\n",
        "  text = str(test_friends['text'][i])\r\n",
        "  label = test_friends['label'][i]\r\n",
        "  #token 만드는 부분\r\n",
        "  token = tokenizer.encode(text, max_length=max_sequence_length,  pad_to_max_length=True)\r\n",
        "  for index, value in enumerate(token):\r\n",
        "    if value == 1:\r\n",
        "        token[index] = 0\r\n",
        "\r\n",
        "  #mask 만드는 부분\r\n",
        "  zeros = token.count(0)\r\n",
        "  mask = [1]*(max_sequence_length-zeros) + [0]*zeros\r\n",
        "\r\n",
        "  #segment 만드는 부분\r\n",
        "  segment = [0]*max_sequence_length\r\n",
        "\r\n",
        "\r\n",
        "  #각 리스트에 저장\r\n",
        "  test_tokens.append(token)\r\n",
        "  test_masks.append(mask)\r\n",
        "  test_segments.append(segment)\r\n",
        "  test_labels.append(label)\r\n",
        "\r\n",
        "# numpy array로 변경\r\n",
        "test_tokens = np.array(test_tokens)\r\n",
        "test_masks = np.array(test_masks)\r\n",
        "test_segments = np.array(test_segments)\r\n",
        "test_labels = np.array(test_labels)\r\n",
        "\r\n",
        "test_x = [test_tokens, test_masks, test_segments]\r\n",
        "test_y = test_labels"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2179: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R10ALK4D_OyM",
        "outputId": "71b6eebe-94a0-45d0-8051-d291fd9bd19f"
      },
      "source": [
        "model = TFBertModel.from_pretrained('bert-base-multilingual-cased', from_pt=True)\r\n",
        "input_tokens = tf.keras.layers.Input((max_sequence_length, ), dtype=tf.int32, name='input_word_ids')\r\n",
        "input_masks = tf.keras.layers.Input((max_sequence_length, ), dtype=tf.int32, name='input_masks')\r\n",
        "input_segments = tf.keras.layers.Input((max_sequence_length, ), dtype=tf.int32, name='input_segment')\r\n",
        "output = model([input_tokens, input_masks, input_segments])\r\n",
        "output = output[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of TFBertModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sFuGWvYK_zow"
      },
      "source": [
        "#embedding = tf.keras.layers.Embedding(768,128)(output)\r\n",
        "lstm = tf.keras.layers.LSTM(128)(output)\r\n",
        "drop = tf.keras.layers.Dropout(0.5)(lstm)\r\n",
        "dense = tf.keras.layers.Dense(8, activation='softmax', kernel_initializer=tf.keras.initializers.TruncatedNormal(stddev=0.02))(drop)\r\n",
        "final_model = tf.keras.Model([input_tokens, input_masks, input_segments], dense)\r\n",
        "final_model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.00001), loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False), metrics = ['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQFofsZPBDla"
      },
      "source": [
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\r\n",
        "\r\n",
        "early_stopping = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=3)\r\n",
        "#model_checkpoint = ModelCheckpoint('/content/gdrive/My Drive/Colab Notebooks/naver_sentiment/Friends/best_model.h5', monitor='val_accuracy', mode='max', verbose=1, save_weights_only=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ipS8nF3xqgo",
        "outputId": "d1069a97-4b21-41e9-abdf-a16be597989b"
      },
      "source": [
        "final_model.fit(train_x, train_y, epochs=30, callbacks=[early_stopping], shuffle=True, batch_size=64, validation_data=(test_x, test_y))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_2/bert/pooler/dense/kernel:0', 'tf_bert_model_2/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_2/bert/pooler/dense/kernel:0', 'tf_bert_model_2/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
            "166/166 [==============================] - ETA: 0s - loss: 1.7639 - accuracy: 0.4507"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r166/166 [==============================] - 164s 876ms/step - loss: 1.7632 - accuracy: 0.4508 - val_loss: 1.4717 - val_accuracy: 0.5365\n",
            "Epoch 2/30\n",
            "166/166 [==============================] - 148s 895ms/step - loss: 1.4823 - accuracy: 0.5280 - val_loss: 1.3949 - val_accuracy: 0.5546\n",
            "Epoch 3/30\n",
            "166/166 [==============================] - 148s 894ms/step - loss: 1.4051 - accuracy: 0.5619 - val_loss: 1.3337 - val_accuracy: 0.5742\n",
            "Epoch 4/30\n",
            "166/166 [==============================] - 148s 894ms/step - loss: 1.3267 - accuracy: 0.5911 - val_loss: 1.2968 - val_accuracy: 0.5792\n",
            "Epoch 5/30\n",
            "166/166 [==============================] - 149s 895ms/step - loss: 1.2463 - accuracy: 0.6241 - val_loss: 1.2661 - val_accuracy: 0.5825\n",
            "Epoch 6/30\n",
            "166/166 [==============================] - 148s 894ms/step - loss: 1.1905 - accuracy: 0.6419 - val_loss: 1.2852 - val_accuracy: 0.5713\n",
            "Epoch 7/30\n",
            "166/166 [==============================] - 149s 895ms/step - loss: 1.1623 - accuracy: 0.6494 - val_loss: 1.2496 - val_accuracy: 0.5872\n",
            "Epoch 8/30\n",
            "166/166 [==============================] - 148s 895ms/step - loss: 1.1114 - accuracy: 0.6744 - val_loss: 1.2578 - val_accuracy: 0.5691\n",
            "Epoch 9/30\n",
            "166/166 [==============================] - 149s 895ms/step - loss: 1.0348 - accuracy: 0.6959 - val_loss: 1.3460 - val_accuracy: 0.5336\n",
            "Epoch 10/30\n",
            "166/166 [==============================] - 148s 894ms/step - loss: 1.0853 - accuracy: 0.6729 - val_loss: 1.2544 - val_accuracy: 0.5724\n",
            "Epoch 00010: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe1c0584b38>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvMEEZms2kGK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5455e63f-3440-43a2-ef9b-c0f5673b7e88"
      },
      "source": [
        "#제출할 데이터\r\n",
        "submit_friends = pd.read_table('/content/gdrive/My Drive/Colab Notebooks/naver_sentiment/제출데이터/en_data.csv', delimiter=',')\r\n",
        "submit_friends.drop(['i_dialog', 'i_utterance', 'speaker'], axis='columns', inplace=True)\r\n",
        "submit_friends"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>utterance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Alright, whadyou do with him?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Oh! You're awake!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Then you gotta come clean with Ma! This is not...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Yeah, but this is</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>I don't wanna hear it! Now go to my room!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1618</th>\n",
              "      <td>1618</td>\n",
              "      <td>Nooo.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1619</th>\n",
              "      <td>1619</td>\n",
              "      <td>Hi, Kate!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1620</th>\n",
              "      <td>1620</td>\n",
              "      <td>Hi, Lauren.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1621</th>\n",
              "      <td>1621</td>\n",
              "      <td>Hi, Lauren.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1622</th>\n",
              "      <td>1622</td>\n",
              "      <td>Hi, pig!</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1623 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        id                                          utterance\n",
              "0        0                      Alright, whadyou do with him?\n",
              "1        1                                  Oh! You're awake!\n",
              "2        2  Then you gotta come clean with Ma! This is not...\n",
              "3        3                                  Yeah, but this is\n",
              "4        4          I don't wanna hear it! Now go to my room!\n",
              "...    ...                                                ...\n",
              "1618  1618                                              Nooo.\n",
              "1619  1619                                          Hi, Kate!\n",
              "1620  1620                                        Hi, Lauren.\n",
              "1621  1621                                        Hi, Lauren.\n",
              "1622  1622                                           Hi, pig!\n",
              "\n",
              "[1623 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qscZzTtV42za",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "edac308f-440d-4001-e4d5-3192ef885529"
      },
      "source": [
        "submit_tokens = []\r\n",
        "submit_masks = []\r\n",
        "submit_segments = []\r\n",
        "max_sequence_length = 64\r\n",
        "for i in range(len(submit_friends)):\r\n",
        "  text = str(submit_friends['utterance'][i])\r\n",
        "  #token 만드는 부분\r\n",
        "  token = tokenizer.encode(text, max_length=max_sequence_length,  pad_to_max_length=True)\r\n",
        "  for index, value in enumerate(token):\r\n",
        "    if value == 1:\r\n",
        "        token[index] = 0\r\n",
        "\r\n",
        "  #mask 만드는 부분\r\n",
        "  zeros = token.count(0)\r\n",
        "  mask = [1]*(max_sequence_length-zeros) + [0]*zeros\r\n",
        "\r\n",
        "  #segment 만드는 부분\r\n",
        "  segment = [0]*max_sequence_length\r\n",
        "\r\n",
        "\r\n",
        "  #각 리스트에 저장\r\n",
        "  submit_tokens.append(token)\r\n",
        "  submit_masks.append(mask)\r\n",
        "  submit_segments.append(segment)\r\n",
        "\r\n",
        "# numpy array로 변경\r\n",
        "submit_tokens = np.array(submit_tokens)\r\n",
        "submit_masks = np.array(submit_masks)\r\n",
        "submit_segments = np.array(submit_segments)\r\n",
        "\r\n",
        "submit_x = [submit_tokens, submit_masks, submit_segments]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2179: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xv_uVjdZoP5e",
        "outputId": "580a5f5e-3a6e-47a8-acfb-9e920fbb17e5"
      },
      "source": [
        "preds = final_model.predict(submit_x)\r\n",
        "print(len(preds))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1623\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yp2gkIb8qytG",
        "outputId": "cd207377-9229-418c-c56a-49e05e250292"
      },
      "source": [
        "submit_friends['Predicted']=''\r\n",
        "for i in range(len(preds)):\r\n",
        "  label = np.argmax(preds[i])\r\n",
        "  if label == 0:\r\n",
        "    label = 'non-neutral'\r\n",
        "  elif label == 1:\r\n",
        "    label = 'neutral'\r\n",
        "  elif label == 2:\r\n",
        "    label = 'joy'\r\n",
        "  elif label == 3:\r\n",
        "    label = 'sadness'\r\n",
        "  elif label == 4:\r\n",
        "    label = 'fear'\r\n",
        "  elif label == 5:\r\n",
        "    label ='anger'\r\n",
        "  elif label == 6:\r\n",
        "    label ='surprise'\r\n",
        "  elif label == 7:\r\n",
        "    label = 'disgust'\r\n",
        "  submit_friends['Predicted'][i] = label\r\n",
        "submit_friends.drop(['utterance'], axis='columns', inplace=True)\r\n",
        "submit_friends.rename(columns = {'id' : 'Id'}, inplace = True)\r\n",
        "submit_friends"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>Predicted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>surprise</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>non-neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>non-neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1618</th>\n",
              "      <td>1618</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1619</th>\n",
              "      <td>1619</td>\n",
              "      <td>joy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1620</th>\n",
              "      <td>1620</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1621</th>\n",
              "      <td>1621</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1622</th>\n",
              "      <td>1622</td>\n",
              "      <td>joy</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1623 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        Id    Predicted\n",
              "0        0      neutral\n",
              "1        1     surprise\n",
              "2        2  non-neutral\n",
              "3        3      neutral\n",
              "4        4  non-neutral\n",
              "...    ...          ...\n",
              "1618  1618      neutral\n",
              "1619  1619          joy\n",
              "1620  1620      neutral\n",
              "1621  1621      neutral\n",
              "1622  1622          joy\n",
              "\n",
              "[1623 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJnLn6FwuQZI"
      },
      "source": [
        "submit_friends.to_csv('/content/gdrive/My Drive/Colab Notebooks/naver_sentiment/제출데이터/friends 데이터 결과2.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}